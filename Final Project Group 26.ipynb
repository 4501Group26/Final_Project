{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import text\n",
    "import re\n",
    "import geopandas as gpd\n",
    "from os.path import exists\n",
    "#!pip install pyarrow\n",
    "#!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any general notebook setup, like log formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(from_coord, to_coord):\n",
    "    lat1=radians(from_coord[0])\n",
    "    lat2=radians(to_coord[0])\n",
    "    lon1=radians(from_coord[1])\n",
    "    lon2=radians(to_coord[1])\n",
    "    dis_lat=lat2-lat1\n",
    "    dis_lon=lon2-lon1\n",
    "    a = sin(dis_lat / 2)**2 + cos(lat1) * cos(lat2) * sin(dis_lon/ 2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return 6371*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    distance_list = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        from_coord = []\n",
    "        to_coord = []\n",
    "        from_coord.append(row['pickup_latitude'])\n",
    "        from_coord.append(row['pickup_longitude'])\n",
    "        to_coord.append(row['dropoff_latitude'])\n",
    "        to_coord.append(row['dropoff_longitude'])\n",
    "        distance_list.append(calculate_distance(from_coord, to_coord))    \n",
    "    dataframe['Distance'] = distance_list\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "**Getting Yellow Taxi URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_csv_urls():\n",
    "    response = requests.get(TAXI_URL)\n",
    "    former_result = response.content\n",
    "    soup = bs4.BeautifulSoup(former_result, 'html.parser')\n",
    "    \n",
    "    result = []\n",
    "    pattern = r\"Yellow Taxi Trip Records\"\n",
    "    data = soup.find_all(\"a\")\n",
    "    for i in range(len(data)):\n",
    "        matches = re.search(pattern, data[i].text)\n",
    "        if type(matches) == re.Match:\n",
    "            result.append(data[i]['href'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c25203",
   "metadata": {},
   "source": [
    "**Define how to get shapefile to convert ID to coordinates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1681ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_and_coordinate(shapefile):\n",
    "    df = gpd.read_file(shapefile)\n",
    "    df=df.to_crs(4326)\n",
    "    #Find the center point\n",
    "    df['Center_point'] = df['geometry'].centroid\n",
    "    #Extract lat and lon from the centerpoint\n",
    "    df[\"longitude\"] = df.Center_point.map(lambda p: p.x)\n",
    "    df[\"latitude\"] = df.Center_point.map(lambda p: p.y)\n",
    "    df = pd.concat([df[\"LocationID\"], df[\"longitude\"], df[\"latitude\"]],axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15737f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ae9c73e78da5>:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df['Center_point'] = df['geometry'].centroid\n",
      "<ipython-input-6-ae9c73e78da5>:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df['Center_point'] = df['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "get_id_and_coordinate(\"taxi_zones.shp\")\n",
    "df_ID_coordinates_pickup = get_id_and_coordinate(\"taxi_zones.shp\")\n",
    "df_ID_coordinates_pickup.columns = [\"PULocationID\",\"pickup_longitude\", \"pickup_latitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22da7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ae9c73e78da5>:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df['Center_point'] = df['geometry'].centroid\n",
      "<ipython-input-6-ae9c73e78da5>:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df['Center_point'] = df['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "get_id_and_coordinate(\"taxi_zones.shp\")\n",
    "df_ID_coordinates_dropoff = get_id_and_coordinate(\"taxi_zones.shp\")\n",
    "df_ID_coordinates_dropoff.columns = [\"DOLocationID\",\"dropoff_longitude\", \"dropoff_latitude\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90542f00",
   "metadata": {},
   "source": [
    "**DownLoad Parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a864f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "    #file_url = url\n",
    "    pattern=r\"[0-9]{4}-[0-9]{2}\"\n",
    "    match = re.search(pattern, url)\n",
    "    fname=match.group()\n",
    "    r = requests.get(url, stream = True)\n",
    "    with open(f\"python{fname}.parquet\",\"wb\") as parquet:\n",
    "        for chunk in r.iter_content(chunk_size=100000):\n",
    "            if chunk:\n",
    "                parquet.write(chunk)\n",
    "\n",
    "    name=f\"python{fname}.parquet\"\n",
    "    df=pd.read_parquet(name,engine='auto')\n",
    "    \n",
    "    \n",
    "   \n",
    "    #df.columns = [\"pickup_datetime\", \"dropoff_datetime\", \"trip_distance\", \"PULocationID\", \"DOLocationID\", \"tip_amount\"]\n",
    "    \n",
    "    if \"Trip_Pickup_DateTime\" in df.columns: #For data in 2009\n",
    "        df.rename(columns={\"Trip_Pickup_DateTime\": \"pickup_datetime\"}, inplace=True)\n",
    "        df.rename(columns={\"Trip_Dropoff_DateTime\": \"dropoff_datetime\"}, inplace=True)\n",
    "        df.rename(columns={\"Trip_Distance\": \"trip_distance\"}, inplace=True)\n",
    "        df.rename(columns={\"Start_Lon\": \"pickup_longitude\"}, inplace=True)\n",
    "        df.rename(columns={\"Start_Lat\": \"pickup_latitude\"}, inplace=True)\n",
    "        df.rename(columns={\"End_Lon\": \"dropoff_longitude\"}, inplace=True)\n",
    "        df.rename(columns={\"End_Lat\": \"dropoff_latitude\"}, inplace=True)\n",
    "        df.rename(columns={\"Tip_Amt\": \"tip_amount\"}, inplace=True)\n",
    "        \n",
    "        df = pd.concat([\n",
    "            df[\"pickup_datetime\"], df[\"dropoff_datetime\"], df[\"trip_distance\"],\n",
    "            df[\"pickup_longitude\"],df[\"pickup_latitude\"], \n",
    "            df[\"dropoff_longitude\"],df[\"dropoff_latitude\"],df[\"tip_amount\"]],axis = 1)\n",
    "    \n",
    "    elif \"pickup_datetime\" in df.columns:  #For data in 2011\n",
    "        df = pd.concat([\n",
    "            df[\"pickup_datetime\"], df[\"dropoff_datetime\"], df[\"trip_distance\"],\n",
    "            df[\"pickup_longitude\"],df[\"pickup_latitude\"], \n",
    "            df[\"dropoff_longitude\"],df[\"dropoff_latitude\"],df[\"tip_amount\"]],axis = 1)\n",
    "\n",
    "    elif \"tpep_pickup_datetime\" in df.columns:  #For data from 2011 to 2022\n",
    "        df.rename(columns={\"tpep_pickup_datetime\": \"pickup_datetime\"}, inplace=True)\n",
    "        df.rename(columns={\"tpep_dropoff_datetime\": \"dropoff_datetime\"}, inplace=True)\n",
    "        df = pd.concat([\n",
    "            df[\"pickup_datetime\"], df[\"dropoff_datetime\"], df[\"trip_distance\"], \n",
    "            df[\"PULocationID\"], df[\"DOLocationID\"],df[\"tip_amount\"]],axis = 1)\n",
    "\n",
    "        df = pd.merge(df, df_ID_coordinates_pickup, how = \"left\", on =\"PULocationID\")\n",
    "        df = pd.merge(df, df_ID_coordinates_dropoff, how = \"left\", on =\"DOLocationID\")\n",
    "        df.drop([\"PULocationID\",\"DOLocationID\"],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    all_csv_urls = find_taxi_csv_urls()\n",
    "    for csv_url in all_csv_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact file already and saved it before trying again\n",
    "\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        pattern=r\"[0-9]{4}-[0-9]{2}\"\n",
    "        match = re.search(pattern, csv_url)\n",
    "        fname=match.group()\n",
    "        \n",
    "        if exists(f\"Yellow_taxi{fname}.csv\"):\n",
    "            dataframe = pd.read_csv(f\"Yellow_taxi{fname}.csv\")\n",
    "            \n",
    "        else:\n",
    "            dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "            dataframe = dataframe.sample(n=2000, random_state=7) #generate samples that's roughly equal to Uber dataset\n",
    "            \n",
    "            add_distance_column(dataframe)\n",
    " \n",
    "        for index, row in dataframe.iterrows():\n",
    "            if row['pickup_latitude']<40.560445:\n",
    "                dataframe = dataframe.drop(index)\n",
    "            elif row['pickup_latitude']>40.908524:\n",
    "                dataframe = dataframe.drop(index)\n",
    "            elif row['dropoff_latitude']<40.560445:\n",
    "                dataframe = dataframe.drop(index)\n",
    "            elif row['dropoff_latitude']>40.908524:\n",
    "                dataframe = dataframe.drop(index)\n",
    "            elif row['pickup_longitude']<-74.242330:\n",
    "                dataframe = dataframe.drop(index)\n",
    "            elif row['pickup_longitude']>-73.717047:\n",
    "                dataframe = dataframe.drop(index)\n",
    "            elif row['dropoff_longitude']<-74.242330:\n",
    "                dataframe = dataframe.drop(index) \n",
    "            elif row['dropoff_longitude']>-73.717047:\n",
    "                dataframe = dataframe.drop(index)\n",
    "\n",
    "        dataframe = dataframe.dropna(axis=0,how='any')\n",
    "\n",
    "        dataframe.to_csv(f\"Yellow_taxi{fname}.csv\", index=False)\n",
    "        #dataframe = pd.read_csv(f\"Yellow_taxi{fname}.csv\")\n",
    "\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76354d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "**Download Uber Data and remove trips out of the box** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    df = pd.read_csv(csv_file,low_memory=False)\n",
    "    df.drop([\"key\",\"fare_amount\",\"passenger_count\",\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "    for index, row in df.iterrows():\n",
    "        if row['pickup_latitude']<40.560445:\n",
    "            df = df.drop(index)\n",
    "        elif row['pickup_latitude']>40.908524:\n",
    "            df = df.drop(index)\n",
    "        elif row['dropoff_latitude']<40.560445:\n",
    "            df = df.drop(index)\n",
    "        elif row['dropoff_latitude']>40.908524:\n",
    "            df = df.drop(index)\n",
    "        elif row['pickup_longitude']<-74.242330:\n",
    "            df = df.drop(index)\n",
    "        elif row['pickup_longitude']>-73.717047:\n",
    "            df = df.drop(index)\n",
    "        elif row['dropoff_longitude']<-74.242330:\n",
    "            df = df.drop(index) \n",
    "        elif row['dropoff_longitude']>-73.717047:\n",
    "            df = df.drop(index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "**Get all the necessary columns in weather data**\n",
    "\n",
    "**Fill in null values with 0 and mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    original_df = pd.read_csv(csv_file ,low_memory=False)\n",
    "    df = pd.concat([original_df[\"DATE\"], original_df[\"HourlyPrecipitation\"], original_df[\"HourlyWindSpeed\"]],axis = 1)\n",
    "    df[\"HourlyPrecipitation\"] = df[\"HourlyPrecipitation\"].replace('T', 0.00)\n",
    "    df[\"HourlyPrecipitation\"] = df[\"HourlyPrecipitation\"].str.replace('s', '')\n",
    "    df[\"HourlyPrecipitation\"] = df[\"HourlyPrecipitation\"].fillna(0.00)\n",
    "    df[\"HourlyWindSpeed\"] = df[\"HourlyWindSpeed\"].fillna(0.00)\n",
    "    df = df[df.DATE.str.contains(\":51:00\")]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    original_df = pd.read_csv(csv_file, low_memory=False)\n",
    "    df = pd.concat([original_df[\"DATE\"], original_df[\"DailyAverageWindSpeed\"],original_df[\"Sunrise\"],original_df[\"Sunset\"]],axis = 1)\n",
    "    df = df[df.DATE.str.contains(\"23:59:00\")]\n",
    "    df[\"DailyAverageWindSpeed\"] = df[\"DailyAverageWindSpeed\"].fillna(df[\"DailyAverageWindSpeed\"].astype(float).mean())\n",
    "    df[\"DailyAverageWindSpeed\"] = df[\"DailyAverageWindSpeed\"].fillna(0.00)\n",
    "    df[\"Sunrise\"] = df[\"Sunrise\"].fillna(df[\"Sunrise\"].astype(float).mean())\n",
    "    df[\"Sunset\"] = df[\"Sunset\"].fillna(df[\"Sunset\"].astype(float).mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    weather_csv_files = [\"2009_weather.csv\", \n",
    "    \"2010_weather.csv\", \"2011_weather.csv\", \n",
    "    \"2012_weather.csv\",\"2013_weather.csv\", \n",
    "    \"2014_weather.csv\", \"2015_weather.csv\",]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "\n",
    "_**Run all the functions above**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()\n",
    "taxi_data = get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16bdffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01T00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01T01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01T02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01T03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01T04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>2015-12-31T19:51:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>2015-12-31T20:51:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>2015-12-31T21:51:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>2015-12-31T22:51:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>2015-12-31T23:51:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60311 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE HourlyPrecipitation  HourlyWindSpeed\n",
       "0      2009-01-01T00:51:00                 0.0             18.0\n",
       "1      2009-01-01T01:51:00                 0.0             18.0\n",
       "2      2009-01-01T02:51:00                 0.0             18.0\n",
       "3      2009-01-01T03:51:00                 0.0              8.0\n",
       "4      2009-01-01T04:51:00                 0.0             11.0\n",
       "...                    ...                 ...              ...\n",
       "11380  2015-12-31T19:51:00                0.00              6.0\n",
       "11381  2015-12-31T20:51:00                0.00             10.0\n",
       "11382  2015-12-31T21:51:00                0.00              0.0\n",
       "11383  2015-12-31T22:51:00                0.00              7.0\n",
       "11384  2015-12-31T23:51:00                0.00              5.0\n",
       "\n",
       "[60311 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b537a5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2009-01-02T23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1640.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2009-01-06T23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1644.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2009-01-07T23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1645.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2009-01-10T23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1648.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2009-01-11T23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1649.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>2015-12-28T23:59:00</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>1636.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>2015-12-29T23:59:00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1636.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>2015-12-30T23:59:00</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1637.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>2015-12-31T23:59:00</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>1638.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>2015-12-31T23:59:00</td>\n",
       "      <td>5.234711</td>\n",
       "      <td>563.813699</td>\n",
       "      <td>1783.90137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE  DailyAverageWindSpeed     Sunrise      Sunset\n",
       "55     2009-01-02T23:59:00               0.000000  720.000000  1640.00000\n",
       "163    2009-01-06T23:59:00               0.000000  720.000000  1644.00000\n",
       "202    2009-01-07T23:59:00               0.000000  720.000000  1645.00000\n",
       "305    2009-01-10T23:59:00               0.000000  720.000000  1648.00000\n",
       "343    2009-01-11T23:59:00               0.000000  720.000000  1649.00000\n",
       "...                    ...                    ...         ...         ...\n",
       "11264  2015-12-28T23:59:00               8.300000  719.000000  1636.00000\n",
       "11312  2015-12-29T23:59:00               7.000000  720.000000  1636.00000\n",
       "11351  2015-12-30T23:59:00               4.100000  720.000000  1637.00000\n",
       "11385  2015-12-31T23:59:00               5.400000  720.000000  1638.00000\n",
       "11386  2015-12-31T23:59:00               5.234711  563.813699  1783.90137\n",
       "\n",
       "[1875 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f5d51fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-26 13:48:50</td>\n",
       "      <td>2022-01-26 13:51:33</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-13 23:53:57</td>\n",
       "      <td>2022-01-14 00:13:07</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.06</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>5.222630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-12 18:57:26</td>\n",
       "      <td>2022-01-12 19:08:02</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.92</td>\n",
       "      <td>-73.988787</td>\n",
       "      <td>40.753513</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>1.426829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04 07:44:15</td>\n",
       "      <td>2022-01-04 07:51:56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-73.968168</td>\n",
       "      <td>40.797962</td>\n",
       "      <td>-73.961764</td>\n",
       "      <td>40.809457</td>\n",
       "      <td>1.387213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-10 18:54:22</td>\n",
       "      <td>2022-01-10 19:06:22</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-74.001538</td>\n",
       "      <td>40.723888</td>\n",
       "      <td>4.768173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>2009-12-29 18:52:00</td>\n",
       "      <td>2009-12-29 19:00:00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.994457</td>\n",
       "      <td>40.755750</td>\n",
       "      <td>-74.002377</td>\n",
       "      <td>40.734517</td>\n",
       "      <td>2.453466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>2009-12-17 16:09:32</td>\n",
       "      <td>2009-12-17 16:33:40</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-74.010487</td>\n",
       "      <td>40.718503</td>\n",
       "      <td>-73.982984</td>\n",
       "      <td>40.782506</td>\n",
       "      <td>7.484408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>2009-12-17 20:25:00</td>\n",
       "      <td>2009-12-17 20:30:00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.999313</td>\n",
       "      <td>40.730922</td>\n",
       "      <td>-73.987767</td>\n",
       "      <td>40.724363</td>\n",
       "      <td>1.215942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>2009-12-23 15:16:00</td>\n",
       "      <td>2009-12-23 15:21:00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.969417</td>\n",
       "      <td>40.756277</td>\n",
       "      <td>-73.957653</td>\n",
       "      <td>40.765547</td>\n",
       "      <td>1.429754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>2009-12-02 18:28:00</td>\n",
       "      <td>2009-12-02 19:14:00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4.54</td>\n",
       "      <td>-73.974060</td>\n",
       "      <td>40.743093</td>\n",
       "      <td>-73.978918</td>\n",
       "      <td>40.763602</td>\n",
       "      <td>2.316919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323264 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_datetime     dropoff_datetime  trip_distance  tip_amount  \\\n",
       "0     2022-01-26 13:48:50  2022-01-26 13:51:33           0.57        1.00   \n",
       "1     2022-01-13 23:53:57  2022-01-14 00:13:07           4.16        4.06   \n",
       "2     2022-01-12 18:57:26  2022-01-12 19:08:02           1.18        1.92   \n",
       "3     2022-01-04 07:44:15  2022-01-04 07:51:56           0.66        1.46   \n",
       "4     2022-01-10 18:54:22  2022-01-10 19:06:22           3.00        1.00   \n",
       "...                   ...                  ...            ...         ...   \n",
       "1959  2009-12-29 18:52:00  2009-12-29 19:00:00           1.82        0.00   \n",
       "1960  2009-12-17 16:09:32  2009-12-17 16:33:40           6.10        0.00   \n",
       "1961  2009-12-17 20:25:00  2009-12-17 20:30:00           0.88        0.00   \n",
       "1962  2009-12-23 15:16:00  2009-12-23 15:21:00           1.19        0.00   \n",
       "1963  2009-12-02 18:28:00  2009-12-02 19:14:00           2.42        4.54   \n",
       "\n",
       "      pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0           -73.996971        40.742279         -73.996971         40.742279   \n",
       "1           -73.965635        40.768615         -74.008984         40.735035   \n",
       "2           -73.988787        40.753513         -73.996971         40.742279   \n",
       "3           -73.968168        40.797962         -73.961764         40.809457   \n",
       "4           -73.965146        40.756729         -74.001538         40.723888   \n",
       "...                ...              ...                ...               ...   \n",
       "1959        -73.994457        40.755750         -74.002377         40.734517   \n",
       "1960        -74.010487        40.718503         -73.982984         40.782506   \n",
       "1961        -73.999313        40.730922         -73.987767         40.724363   \n",
       "1962        -73.969417        40.756277         -73.957653         40.765547   \n",
       "1963        -73.974060        40.743093         -73.978918         40.763602   \n",
       "\n",
       "      Distance  \n",
       "0     0.000000  \n",
       "1     5.222630  \n",
       "2     1.426829  \n",
       "3     1.387213  \n",
       "4     4.768173  \n",
       "...        ...  \n",
       "1959  2.453466  \n",
       "1960  7.484408  \n",
       "1961  1.215942  \n",
       "1962  1.429754  \n",
       "1963  2.316919  \n",
       "\n",
       "[323264 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b6868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.683323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.457590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.036377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.661683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.475450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.112210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1.875050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>12.850319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>3.539715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>5.417783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195473 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "...                         ...               ...              ...   \n",
       "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
       "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
       "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
       "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
       "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude   Distance  \n",
       "0              -73.999512         40.723217   1.683323  \n",
       "1              -73.994710         40.750325   2.457590  \n",
       "2              -73.962565         40.772647   5.036377  \n",
       "3              -73.965316         40.803349   1.661683  \n",
       "4              -73.973082         40.761247   4.475450  \n",
       "...                   ...               ...        ...  \n",
       "199995         -73.986525         40.740297   0.112210  \n",
       "199996         -74.006672         40.739620   1.875050  \n",
       "199997         -73.858957         40.692588  12.850319  \n",
       "199998         -73.983215         40.695415   3.539715  \n",
       "199999         -73.985508         40.768793   5.417783  \n",
       "\n",
       "[195473 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL,echo = True)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    Date DATETIME,\n",
    "    HourlyPrecipitation FLOAT,\n",
    "    HourlyWindSpeed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    Date DATETIME,\n",
    "    DailyAverageWindSpeed FLOAT,\n",
    "    Sunrise FLOAT,\n",
    "    Sunset FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime DATETIME,\n",
    "    dropoff_datetime DATETIME,\t\n",
    "    trip_distance FLOAT,\t\n",
    "    tip_amount FLOAT,\t\n",
    "    pickup_longitude FLOAT,\t\n",
    "    pickup_latitude FLOAT,\t\n",
    "    dropoff_longitude FLOAT,\t\n",
    "    dropoff_latitude FLOAT,\t\n",
    "    Distance FLOAT\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime  DATETIME,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    Distance FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f76229ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "**Use pandas.to_sql to write data to the database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for keys, values in table_to_df_dict.items():\n",
    "        values.to_sql(keys, con=engine,if_exists='replace', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74004f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:07:29,140 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"taxi_trips\")\n",
      "2022-12-07 14:07:29,142 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:29,150 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"taxi_trips\")\n",
      "2022-12-07 14:07:29,151 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:29,158 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:29,162 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE taxi_trips (\n",
      "\tpickup_datetime TEXT, \n",
      "\tdropoff_datetime TEXT, \n",
      "\ttrip_distance FLOAT, \n",
      "\ttip_amount FLOAT, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\t\"Distance\" FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-12-07 14:07:29,164 INFO sqlalchemy.engine.Engine [no key 0.00220s] ()\n",
      "2022-12-07 14:07:29,173 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:30,113 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:34,817 INFO sqlalchemy.engine.Engine INSERT INTO taxi_trips (pickup_datetime, dropoff_datetime, trip_distance, tip_amount, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, \"Distance\") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2022-12-07 14:07:34,819 INFO sqlalchemy.engine.Engine [generated in 3.34982s] (('2022-01-26 13:48:50', '2022-01-26 13:51:33', 0.57, 1.0, -73.99697141558364, 40.74227862901228, -73.99697141558364, 40.74227862901228, 0.0), ('2022-01-13 23:53:57', '2022-01-14 00:13:07', 4.16, 4.06, -73.96563453538072, 40.76861518381155, -74.0089841047853, 40.73503540069664, 5.222630173656859), ('2022-01-12 18:57:26', '2022-01-12 19:08:02', 1.18, 1.92, -73.9887865991153, 40.75351275872571, -73.99697141558364, 40.74227862901228, 1.4268292782956946), ('2022-01-04 07:44:15', '2022-01-04 07:51:56', 0.66, 1.46, -73.9681683330924, 40.79796199310004, -73.96176359682921, 40.80945696112528, 1.387212733011227), ('2022-01-10 18:54:22', '2022-01-10 19:06:22', 3.0, 1.0, -73.96514579918421, 40.75672894163307, -74.00153756565634, 40.72388811004171, 4.768173436134829), ('2022-01-24 18:14:10', '2022-01-24 18:21:18', 1.21, 1.08, -73.97769793122403, 40.758028043526274, -73.99513522075517, 40.766237725041854, 1.7292012956172913), ('2022-01-09 00:57:35', '2022-01-09 01:09:48', 3.97, 7.16, -73.99697141558364, 40.74227862901228, -73.94889145447954, 40.74537943399857, 4.065154444055666), ('2022-01-08 18:54:33', '2022-01-08 19:13:24', 3.5, 5.6, -73.98984464313301, 40.762252755319366, -73.9681683330924, 40.79796199310004, 4.370062018820145)  ... displaying 10 of 323264 total bound parameter sets ...  ('2009-12-23 15:16:00', '2009-12-23 15:21:00', 1.19, 0.0, -73.969417, 40.756277, -73.95765299999998, 40.765547, 1.4297543675958968), ('2009-12-02 18:28:00', '2009-12-02 19:14:00', 2.42, 4.54, -73.97405999999998, 40.743093, -73.97891799999998, 40.763602, 2.3169190385968443))\n",
      "2022-12-07 14:07:36,305 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:36,637 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"uber_trips\")\n",
      "2022-12-07 14:07:36,639 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:36,643 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"uber_trips\")\n",
      "2022-12-07 14:07:36,646 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:36,653 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:36,655 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE uber_trips (\n",
      "\tpickup_datetime TEXT, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\t\"Distance\" FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-12-07 14:07:36,662 INFO sqlalchemy.engine.Engine [no key 0.00657s] ()\n",
      "2022-12-07 14:07:36,668 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:36,806 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:39,491 INFO sqlalchemy.engine.Engine INSERT INTO uber_trips (pickup_datetime, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, \"Distance\") VALUES (?, ?, ?, ?, ?, ?)\n",
      "2022-12-07 14:07:39,493 INFO sqlalchemy.engine.Engine [generated in 1.86467s] (('2015-05-07 19:52:06 UTC', -73.99981689453125, 40.73835372924805, -73.99951171875, 40.72321701049805, 1.683322752402931), ('2009-07-17 20:04:56 UTC', -73.994355, 40.728225, -73.99471, 40.750325, 2.4575898837790584), ('2009-08-24 21:45:00 UTC', -74.005043, 40.74077, -73.962565, 40.772647, 5.036377190242993), ('2009-06-26 08:22:21 UTC', -73.976124, 40.790844, -73.965316, 40.803349, 1.661683458435346), ('2014-08-28 17:47:00 UTC', -73.925023, 40.744085, -73.97308199999999, 40.761247, 4.475449963028176), ('2011-02-12 02:27:09 UTC', -73.96901899999999, 40.75591, -73.96901899999999, 40.75591, 0.0), ('2014-10-12 07:04:00 UTC', -73.96144699999999, 40.693965000000006, -73.871195, 40.774297, 11.731014883538434), ('2012-02-17 09:32:00 UTC', -73.975187, 40.745767, -74.00272, 40.743537, 2.332711009340077)  ... displaying 10 of 195473 total bound parameter sets ...  ('2015-05-20 14:56:25 UTC', -73.99712371826173, 40.7254524230957, -73.98321533203125, 40.69541549682617, 3.539715451744548), ('2010-05-15 04:08:00 UTC', -73.98439499999999, 40.720077, -73.985508, 40.768793, 5.417783481056892))\n",
      "2022-12-07 14:07:40,008 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:40,059 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"hourly_weather\")\n",
      "2022-12-07 14:07:40,061 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:40,063 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"hourly_weather\")\n",
      "2022-12-07 14:07:40,071 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:40,077 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:40,086 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE hourly_weather (\n",
      "\t\"DATE\" TEXT, \n",
      "\t\"HourlyPrecipitation\" TEXT, \n",
      "\t\"HourlyWindSpeed\" FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-12-07 14:07:40,116 INFO sqlalchemy.engine.Engine [no key 0.03081s] ()\n",
      "2022-12-07 14:07:40,138 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:40,188 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:40,866 INFO sqlalchemy.engine.Engine INSERT INTO hourly_weather (\"DATE\", \"HourlyPrecipitation\", \"HourlyWindSpeed\") VALUES (?, ?, ?)\n",
      "2022-12-07 14:07:40,867 INFO sqlalchemy.engine.Engine [generated in 0.51915s] (('2009-01-01T00:51:00', 0.0, 18.0), ('2009-01-01T01:51:00', 0.0, 18.0), ('2009-01-01T02:51:00', 0.0, 18.0), ('2009-01-01T03:51:00', 0.0, 8.0), ('2009-01-01T04:51:00', 0.0, 11.0), ('2009-01-01T05:51:00', 0.0, 18.0), ('2009-01-01T06:51:00', 0.0, 14.0), ('2009-01-01T07:51:00', 0.0, 8.0)  ... displaying 10 of 60311 total bound parameter sets ...  ('2015-12-31T22:51:00', '0.00', 7.0), ('2015-12-31T23:51:00', '0.00', 5.0))\n",
      "2022-12-07 14:07:40,994 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:41,005 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2022-12-07 14:07:41,006 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:41,009 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"daily_weather\")\n",
      "2022-12-07 14:07:41,021 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-12-07 14:07:41,043 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:41,065 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE daily_weather (\n",
      "\t\"DATE\" TEXT, \n",
      "\t\"DailyAverageWindSpeed\" FLOAT, \n",
      "\t\"Sunrise\" FLOAT, \n",
      "\t\"Sunset\" FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-12-07 14:07:41,094 INFO sqlalchemy.engine.Engine [no key 0.02976s] ()\n",
      "2022-12-07 14:07:41,151 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-12-07 14:07:41,165 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-12-07 14:07:41,249 INFO sqlalchemy.engine.Engine INSERT INTO daily_weather (\"DATE\", \"DailyAverageWindSpeed\", \"Sunrise\", \"Sunset\") VALUES (?, ?, ?, ?)\n",
      "2022-12-07 14:07:41,250 INFO sqlalchemy.engine.Engine [generated in 0.06802s] (('2009-01-02T23:59:00', 0.0, 720.0, 1640.0), ('2009-01-06T23:59:00', 0.0, 720.0, 1644.0), ('2009-01-07T23:59:00', 0.0, 720.0, 1645.0), ('2009-01-10T23:59:00', 0.0, 720.0, 1648.0), ('2009-01-11T23:59:00', 0.0, 720.0, 1649.0), ('2009-01-15T23:59:00', 0.0, 718.0, 1653.0), ('2009-01-18T23:59:00', 0.0, 717.0, 1656.0), ('2009-01-19T23:59:00', 0.0, 716.0, 1658.0)  ... displaying 10 of 1875 total bound parameter sets ...  ('2015-12-31T23:59:00', 5.4, 720.0, 1638.0), ('2015-12-31T23:59:00', 5.234710743801652, 563.813698630137, 1783.9013698630138))\n",
      "2022-12-07 14:07:41,263 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "connection = engine.connect()\n",
    "write_dataframes_to_table(map_table_name_to_dataframe)  #sometimes went wrong with if_exists=\"replace\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b2570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 project.db < schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e06020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f032b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    with open (outfile,\"w\") as file:\n",
    "        file.write(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f298ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL,echo = True)\n",
    "connection = engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbdecc",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf997dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:07:52,965 INFO sqlalchemy.engine.Engine \n",
      "SELECT strftime ('%H',pickup_datetime) AS Hour_Taxi,\n",
      "COUNT(strftime ('%H',pickup_datetime))\n",
      "FROM taxi_trips\n",
      "WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
      "AND pickup_datetime <= '2015-06-30 23:59:59'\n",
      "GROUP BY Hour_Taxi\n",
      "\n",
      "2022-12-07 14:07:52,969 INFO sqlalchemy.engine.Engine [generated in 0.00367s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('00', 6059),\n",
       " ('01', 4544),\n",
       " ('02', 3322),\n",
       " ('03', 2446),\n",
       " ('04', 1754),\n",
       " ('05', 1487),\n",
       " ('06', 3178),\n",
       " ('07', 5523),\n",
       " ('08', 6777),\n",
       " ('09', 7077),\n",
       " ('10', 6889),\n",
       " ('11', 7022),\n",
       " ('12', 7505),\n",
       " ('13', 7500),\n",
       " ('14', 7492),\n",
       " ('15', 7260),\n",
       " ('16', 6213),\n",
       " ('17', 7729),\n",
       " ('18', 9070),\n",
       " ('19', 9542),\n",
       " ('20', 9019),\n",
       " ('21', 8781),\n",
       " ('22', 8547),\n",
       " ('23', 7540)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_Q1 = '''\n",
    "SELECT strftime ('%H',pickup_datetime) AS Hour_Taxi,\n",
    "COUNT(strftime ('%H',pickup_datetime))\n",
    "FROM taxi_trips\n",
    "WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
    "AND pickup_datetime <= '2015-06-30 23:59:59'\n",
    "GROUP BY Hour_Taxi\n",
    "'''\n",
    "connection.execute(text(QUERY_Q1)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e991b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_Q1, \"QUERT_Q1_most_popular_Yellow_Taxi.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b4a74",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f01ac4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:07:58,718 INFO sqlalchemy.engine.Engine \n",
      "SELECT strftime ('%w',substr(pickup_datetime, 1, 19)) AS WeekDay,\n",
      "COUNT(strftime ('%w',substr(pickup_datetime, 1, 19)))\n",
      "FROM uber_trips\n",
      "WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
      "AND pickup_datetime <= '2015-06-30 23:59:59'\n",
      "GROUP BY WeekDay\n",
      "ORDER BY COUNT(strftime ('%w',substr(pickup_datetime, 1, 19)))\n",
      "\n",
      "2022-12-07 14:07:58,725 INFO sqlalchemy.engine.Engine [generated in 0.00757s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1', 24681),\n",
       " ('0', 25834),\n",
       " ('2', 27527),\n",
       " ('3', 28328),\n",
       " ('4', 29338),\n",
       " ('6', 29599),\n",
       " ('5', 30166)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_Q2 ='''\n",
    "SELECT strftime ('%w',substr(pickup_datetime, 1, 19)) AS WeekDay,\n",
    "COUNT(strftime ('%w',substr(pickup_datetime, 1, 19)))\n",
    "FROM uber_trips\n",
    "WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
    "AND pickup_datetime <= '2015-06-30 23:59:59'\n",
    "GROUP BY WeekDay\n",
    "ORDER BY COUNT(strftime ('%w',substr(pickup_datetime, 1, 19)))\n",
    "'''\n",
    "connection.execute(text(QUERY_Q2)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2662f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_Q2, \"QUERT_Q2_most_popular_Wday_uber.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4d263",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae90ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:08:22,277 INFO sqlalchemy.engine.Engine \n",
      "SELECT Distance\n",
      "FROM (\n",
      "    SELECT Distance\n",
      "    FROM uber_trips\n",
      "    WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
      "    AND pickup_datetime <= '2013-07-31 23:59:59'\n",
      "    AND Distance != 'None'\n",
      "    AND Distance != 0\n",
      "    UNION ALL\n",
      "    SELECT Distance\n",
      "    FROM taxi_trips\n",
      "    WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
      "    AND pickup_datetime <= '2013-07-31 23:59:59'\n",
      "    AND Distance != 'None'\n",
      "    AND Distance != 0\n",
      "    )\n",
      "    ORDER BY Distance\n",
      "    LIMIT 1\n",
      "    OFFSET(\n",
      "        SELECT COUNT(*)\n",
      "        FROM uber_trips\n",
      "        WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
      "        AND pickup_datetime <= '2013-07-31 23:59:59'\n",
      "        AND Distance != 'None'\n",
      "        AND Distance != 0\n",
      "        UNION ALL\n",
      "        SELECT Distance\n",
      "        FROM taxi_trips\n",
      "        WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
      "        AND pickup_datetime <= '2013-07-31 23:59:59'\n",
      "        AND Distance != 'None'\n",
      "        AND Distance != 0\n",
      "        )*95/100-1\n",
      "        \n",
      "2022-12-07 14:08:22,279 INFO sqlalchemy.engine.Engine [generated in 0.00190s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.5432487944601734,)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_Q3 ='''\n",
    "SELECT Distance\n",
    "FROM (\n",
    "    SELECT Distance\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
    "    AND pickup_datetime <= '2013-07-31 23:59:59'\n",
    "    AND Distance != 'None'\n",
    "    AND Distance != 0\n",
    "    UNION ALL\n",
    "    SELECT Distance\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
    "    AND pickup_datetime <= '2013-07-31 23:59:59'\n",
    "    AND Distance != 'None'\n",
    "    AND Distance != 0\n",
    "    )\n",
    "    ORDER BY Distance\n",
    "    LIMIT 1\n",
    "    OFFSET(\n",
    "        SELECT COUNT(*)\n",
    "        FROM uber_trips\n",
    "        WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
    "        AND pickup_datetime <= '2013-07-31 23:59:59'\n",
    "        AND Distance != 'None'\n",
    "        AND Distance != 0\n",
    "        UNION ALL\n",
    "        SELECT Distance\n",
    "        FROM taxi_trips\n",
    "        WHERE pickup_datetime >= '2013-07-01 00:00:00'\n",
    "        AND pickup_datetime <= '2013-07-31 23:59:59'\n",
    "        AND Distance != 'None'\n",
    "        AND Distance != 0\n",
    "        )*95/100-1\n",
    "        '''\n",
    "connection.execute(text(QUERY_Q3)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d8f8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_Q3, \"QUERT_Q3_95percent_distance_all_hired_trips.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4555a4ff",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5903e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:08:30,537 INFO sqlalchemy.engine.Engine \n",
      "SELECT strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19))) AS DAY,\n",
      "COUNT(strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19)))),\n",
      "avg(Distance)\n",
      "FROM (\n",
      "    SELECT pickup_datetime, Distance\n",
      "    FROM uber_trips\n",
      "    WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
      "    AND pickup_datetime <= '2009-12-31 23:59:59'\n",
      "    AND Distance != 'None'\n",
      "    AND Distance != 0\n",
      "    UNION ALL\n",
      "    SELECT pickup_datetime, Distance\n",
      "    FROM taxi_trips\n",
      "    WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
      "    AND pickup_datetime <= '2009-12-31 23:59:59'\n",
      "    AND Distance != 'None'\n",
      "    AND Distance != 0\n",
      "    )\n",
      "    GROUP BY DAY\n",
      "    ORDER BY Distance\n",
      "    LIMIT 10\n",
      "    \n",
      "2022-12-07 14:08:30,541 INFO sqlalchemy.engine.Engine [generated in 0.00379s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2009-05-28', 162, 2.8110381393187707),\n",
       " ('2009-11-18', 160, 2.563913204033052),\n",
       " ('2009-12-09', 168, 2.9993966201249775),\n",
       " ('2009-10-22', 160, 3.0865799424076346),\n",
       " ('2009-03-31', 143, 2.92322748862072),\n",
       " ('2009-11-12', 164, 3.26071309689255),\n",
       " ('2009-01-27', 164, 2.750322839887795),\n",
       " ('2009-05-04', 118, 3.098580047489864),\n",
       " ('2009-04-28', 144, 3.137438076436413),\n",
       " ('2009-03-24', 128, 3.5134419429161303)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_Q4='''\n",
    "SELECT strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19))) AS DAY,\n",
    "COUNT(strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19)))),\n",
    "avg(Distance)\n",
    "FROM (\n",
    "    SELECT pickup_datetime, Distance\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
    "    AND pickup_datetime <= '2009-12-31 23:59:59'\n",
    "    AND Distance != 'None'\n",
    "    AND Distance != 0\n",
    "    UNION ALL\n",
    "    SELECT pickup_datetime, Distance\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_datetime >= '2009-01-01 00:00:00'\n",
    "    AND pickup_datetime <= '2009-12-31 23:59:59'\n",
    "    AND Distance != 'None'\n",
    "    AND Distance != 0\n",
    "    )\n",
    "    GROUP BY DAY\n",
    "    ORDER BY Distance\n",
    "    LIMIT 10\n",
    "    '''\n",
    "connection.execute(text(QUERY_Q4)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d39c4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_Q4, \"QUERT_Q4_10days_highest_rides_average_distances_2009.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9713879",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70084471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:08:34,182 INFO sqlalchemy.engine.Engine \n",
      "SELECT strftime('%Y-%m-%d',datetime(substr(DATE, 1, 19))) AS DAY,\n",
      "DailyAverageWindSpeed,\n",
      "count\n",
      "FROM daily_weather\n",
      "JOIN(\n",
      "    SELECT DAY_sub, COUNT(*) as count\n",
      "    FROM (\n",
      "        SELECT strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19))) AS DAY_sub, Distance\n",
      "        FROM uber_trips\n",
      "        WHERE pickup_datetime >= '2014-01-01 00:00:00'\n",
      "        AND pickup_datetime <= '2014-12-31 23:59:59'\n",
      "        AND Distance != 'None'\n",
      "        AND Distance != 0\n",
      "        UNION ALL\n",
      "        SELECT strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19))) AS DAY_sub, Distance\n",
      "        FROM taxi_trips\n",
      "        WHERE pickup_datetime >= '2014-01-01 00:00:00'\n",
      "        AND pickup_datetime <= '2014-12-31 23:59:59'\n",
      "        AND Distance != 'None'\n",
      "        AND Distance != 0\n",
      "        )\n",
      "        GROUP BY DAY_sub\n",
      "        ) AS Hired_rides\n",
      "        ON DAY = Hired_rides.DAY_sub\n",
      "        ORDER BY DailyAverageWindSpeed DESC\n",
      "        LIMIT 10\n",
      "    \n",
      "2022-12-07 14:08:34,185 INFO sqlalchemy.engine.Engine [generated in 0.00385s] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2014-03-13', 14.1, 159),\n",
       " ('2014-01-07', 13.1, 138),\n",
       " ('2014-02-13', 12.6, 132),\n",
       " ('2014-01-02', 12.2, 102),\n",
       " ('2014-03-26', 11.9, 158),\n",
       " ('2014-12-07', 11.8, 127),\n",
       " ('2014-12-08', 11.5, 137),\n",
       " ('2014-03-29', 10.8, 182),\n",
       " ('2014-11-02', 10.8, 140),\n",
       " ('2014-01-03', 10.4, 83)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_Q5='''\n",
    "SELECT strftime('%Y-%m-%d',datetime(substr(DATE, 1, 19))) AS DAY,\n",
    "DailyAverageWindSpeed,\n",
    "count\n",
    "FROM daily_weather\n",
    "JOIN(\n",
    "    SELECT DAY_sub, COUNT(*) as count\n",
    "    FROM (\n",
    "        SELECT strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19))) AS DAY_sub, Distance\n",
    "        FROM uber_trips\n",
    "        WHERE pickup_datetime >= '2014-01-01 00:00:00'\n",
    "        AND pickup_datetime <= '2014-12-31 23:59:59'\n",
    "        AND Distance != 'None'\n",
    "        AND Distance != 0\n",
    "        UNION ALL\n",
    "        SELECT strftime('%Y-%m-%d',datetime(substr(pickup_datetime, 1, 19))) AS DAY_sub, Distance\n",
    "        FROM taxi_trips\n",
    "        WHERE pickup_datetime >= '2014-01-01 00:00:00'\n",
    "        AND pickup_datetime <= '2014-12-31 23:59:59'\n",
    "        AND Distance != 'None'\n",
    "        AND Distance != 0\n",
    "        )\n",
    "        GROUP BY DAY_sub\n",
    "        ) AS Hired_rides\n",
    "        ON DAY = Hired_rides.DAY_sub\n",
    "        ORDER BY DailyAverageWindSpeed DESC\n",
    "        LIMIT 10\n",
    "    '''\n",
    "connection.execute(text(QUERY_Q5)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d893ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_Q5, \"QUERT_Q5_10days_windest_number_hiredtrips_2014.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d2249",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_N, \"some_descriptive_name.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9385366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6059, 4544, 3322, 2446, 1754, 1487, 3178, 5523, 6777, 7077, 6889, 7022, 7505, 7500, 7492, 7260, 6213, 7729, 9070, 9542, 9019, 8781, 8547, 7540]\n",
      "['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"
     ]
    }
   ],
   "source": [
    "#Read SQL Query for Q1\n",
    "df_Q1= pd.read_sql_query(QUERY_Q1,DATABASE_URL)\n",
    "df_Q1=df_Q1.rename({'COUNT(strftime (\"%H\",pickup_datetime))':\"COUNT\"}, axis='columns')\n",
    "lst_y=[]\n",
    "lst_x=[]\n",
    "for i in df_Q1[\"COUNT(strftime ('%H',pickup_datetime))\"]:\n",
    "    lst_y.append(i)\n",
    "for i in df_Q1[\"Hour_Taxi\"]:\n",
    "    lst_x.append(i)\n",
    "print(lst_y)\n",
    "print(lst_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1fdeb71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization Q1\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Yellow Taxi Trip Count\")\n",
    "plt.bar(lst_x, lst_y, color=(0.1, 0.1, 0.1, 0.1),  edgecolor='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3687df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4db2a208f45c17d1b9fa3c4c9ef341f150933fc01b6f707b8f7d6d7febdffd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
